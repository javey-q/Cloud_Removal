Project: Rsipac_CR
Experiment:
  name: &name GLF_CR_Base_2:1
  checkpoint_dir: !!python/object/apply:os.path.join ["./experiments", *name, "checkpoints"]
  result_dir: !!python/object/apply:os.path.join ["./experiments", *name, "results"]
  log_dir:
  resume:
#    resume_epoch: 50
#    resume_ckpt: checkpoint_best.pth
#    resume_wandb: f7qm9b1n
#    resume_addition: true

manual_seed: 42
Accelerator:
  gradient_accumulation_steps: 1


datasets:
  train:
    name: Real_CR
    phase: train
    root:  ../Dataset/Rsipac/train_256
    meta_info: ../Dataset/Rsipac/train_256/train_val_list.csv
    io_backend:
      type: disk

    # image settings
    use_cloudmask: false
    cloud_threshold: 0.2
    random_crop: true
    base_size: 256
    crop_size: 256
    use_gray: &use_gray false

    # dataloader
    batch_size: 2
    use_shuffle: true

  val:
    name: Real_CR
    phase: val
    root: ../Dataset/Rsipac/train_256
    meta_info: ../Dataset/Rsipac/train_256/train_val_list.csv
    io_backend:
      type: disk

    # image settings
    use_cloudmask: false
    cloud_threshold: 0.2
    random_crop: true
    base_size: 256
    crop_size: 256
    use_gray: *use_gray
    # dataloader
    batch_size: 2

#  val_2:

network_g:
  name: GLF_CR_Net
  fig_size: 256
  opt_channel: 3
  sar_channel: 2
  RDB_number: 5
  Conv_layers: 5
  Initial_channel: 96
  Out_channels: 48
  use_gray: *use_gray

train:
  epochs: 120
  optimizer_g:
    type: AdamW
    args:
      lr: !!float 1e-4
      weight_decay: 0.
      betas: [0.9, 0.9]
  scheduler:
    type: TrueCosineAnnealingLR
    args:
      T_max: 120  # step
      eta_min: !!float 1e-7
  loss_funs:
    pixel: l1
    ssim: ssim
  loss_weights: [1, 2]

save_epoch_freq: 10
log_step_freq: 100
visual_step_freq: 1000
valid_visual_step_freq: 1000

